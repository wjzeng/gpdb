-- Misc tests related to dispatching queries to segments.
CREATE DATABASE dispatch_test_db;
\c dispatch_test_db;

CREATE EXTENSION IF NOT EXISTS gp_inject_fault;

-- Mask out the whoami message
-- start_matchsubs
-- m/^ \(seg\d .*:\d+\)/
-- s/^ \(seg\d .*:\d+\)//
-- m/^DETAIL:  Internal error: No motion listener port \(seg\d.*:.*\)/
-- s/^DETAIL:  Internal error: No motion listener port \(seg\d.*:.*\)/DETAIL:  Internal error: No motion listener port/
-- end_matchsubs

-- Test quoting of GUC values and database names when they're sent to segments

-- set_config() used to have quoting problems as well when dispatching to
-- segments.
DROP TABLE IF EXISTS should_be_visible;
CREATE TABLE should_be_visible();

CREATE TABLE distribute_table_oid_to_all_segs (distribution_key INT, tbl OID) DISTRIBUTED RANDOMLY;
INSERT INTO distribute_table_oid_to_all_segs SELECT *, 'public.should_be_visible'::regclass FROM generate_series(1, 10);

-- Spin up any gangs necessary to handle the SELECT DISTINCT so that they
-- receive the new search_path setting from the set_config() dispatch.
SELECT DISTINCT pg_catalog.pg_table_is_visible(tbl) FROM distribute_table_oid_to_all_segs;

-- Now change search_path. This setting should not affect the visibility of the
-- public schema if it's dispatched correctly.
SELECT set_config('search_path', 'pg_catalog,public', false);

-- Check that our test table is still visible.
SELECT DISTINCT pg_catalog.pg_table_is_visible(tbl) FROM distribute_table_oid_to_all_segs;

RESET search_path;

-- There used to be a bug in the quoting when the search_path setting was sent
-- to the segment. It was not easily visible when search_path was set with a
-- SET command, only when the setting was sent as part of the startup packet.
-- Set search_path as a per-user setting so that we can test that.
CREATE DATABASE "dispatch test db";
ALTER DATABASE "dispatch test db" SET search_path="my schema",public;

\c "dispatch test db"

CREATE SCHEMA "my schema";

-- Create a table with the same name in both schemas, "my schema" and public.
CREATE TABLE "my table" (t text);
INSERT INTO "my table" VALUES ('myschema.mytable');

CREATE TABLE public."my table" (t text);
INSERT INTO public."my table" VALUES ('public.mytable');

SELECT t as unquoted FROM "my table";
SELECT t as myschema FROM "my schema"."my table";
SELECT t as public FROM public."my table";

DROP TABLE "my table";
DROP TABLE public."my table";

-- Create another table with the same name. To make sure the DROP worked
-- and dropped the correct table.
CREATE TABLE "my table" (id integer);
DROP TABLE "my table";

-- Clean up
\c dispatch_test_db
DROP DATABASE "dispatch test db";

-- Test gp_max_plan_size limit
set gp_max_plan_size='10 kB';
create table dispatchtesttab(t text);
select * from dispatchtesttab where t = repeat('x', 1024*11);

--
-- test QD will report failure if QE fails to send its motion_listener back
-- during backend initialization
--

select gp_inject_fault('send_qe_details_init_backend', 'reset', 2);
-- inject a 'skip' fault before QE sends its motion_listener
select gp_inject_fault('send_qe_details_init_backend', 'skip', 2);

-- terminate exiting QEs first
\c dispatch_test_db
-- verify failure will be reported
SELECT 1 FROM gp_dist_random('gp_id');

-- reset fault injector
select gp_inject_fault('send_qe_details_init_backend', 'reset', 2);


--
-- Test suit : test gang creation and commands dispatching 
--
--start_ignore
drop table if exists dispatch_test;
drop table if exists dispatch_test_t1;
drop table if exists dispatch_test_t2;
drop table if exists dispatch_test_t3;
--end_ignore
create table dispatch_test as select i as c1 from generate_series(1, 10) i;
create table dispatch_test_t1 (c1 int, c2 int, c3 int);
create table dispatch_test_t2 (c1 int, c2 int, c3 int);
create table dispatch_test_t3 (c1 int, c2 int, c3 int);
insert into dispatch_test_t1 values (1,1,2);
insert into dispatch_test_t2 values (2,1,2);
insert into dispatch_test_t3 values (3,1,2);

CREATE OR REPLACE FUNCTION cleanupAllGangs() RETURNS BOOL
AS '@abs_builddir@/regress@DLSUFFIX@', 'cleanupAllGangs' LANGUAGE C;

-- check if segments has backend running
CREATE OR REPLACE FUNCTION hasBackendsExist(int) RETURNS BOOL 
AS '@abs_builddir@/regress@DLSUFFIX@', 'hasBackendsExist' LANGUAGE C;

-- check if QD has reusable gangs
CREATE OR REPLACE FUNCTION hasGangsExist() RETURNS BOOL
AS '@abs_builddir@/regress@DLSUFFIX@', 'hasGangsExist' LANGUAGE C;

-- disable debug linger to get immediate feedback from FATAL errors.
set gp_debug_linger to 0;

-- test log debug related code within dispatch
set gp_log_gang to debug;
set log_min_messages to DEBUG;

-- Case 1.1
-- A segment in recovery mode, writer gang retry gp_gang_creation_retry_count times and finally success

-- set maximum retry time to 120 seconds, this should be long enough for segment
-- recovery back. otherwise it should be bug somewhere
set gp_gang_creation_retry_count to 120;
set gp_gang_creation_retry_timer to 1000;

select cleanupAllGangs();

-- trigger fault and report segment 0 in recovery for 5 times
select gp_inject_fault_new('process_startup_packet', 'skip', '', 'dispatch_test_db', '', 1, 5, 0, 2::smallint);
select cleanupAllGangs();

-- should success after retry
select * from dispatch_test_t1, dispatch_test_t2, dispatch_test_t3
where dispatch_test_t1.c2 = dispatch_test_t2.c2 and dispatch_test_t2.c3 = dispatch_test_t3.c3;

select gp_inject_fault('process_startup_packet', 'reset', 2);

-- Case 1.2
-- A segment in recovery mode for long time, writer gang retry gp_gang_creation_retry_count times and finally failed
-- set maximun retry time to 0.4s, so we can test if gp_gang_creation_retry_count
-- is actually work
set gp_gang_creation_retry_count to 2;
set gp_gang_creation_retry_timer to 200;
select cleanupAllGangs();

-- trigger fault and put segment 0 into recovery mode
select gp_inject_fault_new('process_startup_packet', 'skip', '', 'dispatch_test_db', '', 1, 5, 0, 2::smallint);
select cleanupAllGangs();

-- should failed after 2 times
select * from dispatch_test_t1, dispatch_test_t2, dispatch_test_t3
where dispatch_test_t1.c2 = dispatch_test_t2.c2 and dispatch_test_t2.c3 = dispatch_test_t3.c3;

set gp_gang_creation_retry_count to 10;
-- should success and process_startup_packet will be invalid after this query
select * from dispatch_test_t1, dispatch_test_t2, dispatch_test_t3
where dispatch_test_t1.c2 = dispatch_test_t2.c2 and dispatch_test_t2.c3 = dispatch_test_t3.c3;

select gp_inject_fault('process_startup_packet', 'reset', 2);

--start_ignore
-- enlarge the retry count
set gp_gang_creation_retry_count to 128 ;
-- this will block until segment 0 recovery back, or report an error
-- after 24 seconds.
select 'wait recovery finish' from gp_dist_random('gp_id');
--end_ignore

-- cleanup all reusable gangs 
select cleanupAllGangs();

-- expect no zombie backends left on segments 
select sum(case when hasBackendsExist(30)='t' then 1 else 0 end) > 0 as hasbackends from gp_dist_random('gp_id');

-- should success 
select * from dispatch_test_t1, dispatch_test_t2, dispatch_test_t3
where dispatch_test_t1.c2 = dispatch_test_t2.c2 and dispatch_test_t2.c3 = dispatch_test_t3.c3;

-- Case 1.3
-- segment has non in-recovery-mode errors
-- when creating writer gang, an error reported and all gangs should be cleaned.
-- when creating reader gang, an error reported and only current gang is cleaned.
select cleanupAllGangs();

-- Segment 0 should report an error upon getting a request.  The
-- _new() API ensures that the fault is triggered exactly once.
select gp_inject_fault_new('send_qe_details_init_backend', 'error', 2);

-- expect failure
select * from dispatch_test_t1, dispatch_test_t2, dispatch_test_t3
where dispatch_test_t1.c2 = dispatch_test_t2.c2 and dispatch_test_t2.c3 = dispatch_test_t3.c3;

-- expect no resuable gang exist
select * from hasGangsExist();

-- expect no zombie backends left on segments.
select sum(case when hasBackendsExist(30)='t' then 1 else 0 end) > 0 as hasbackends from gp_dist_random('gp_id');

-- cleanupAllGangs();
select cleanupAllGangs();

select gp_inject_fault('send_qe_details_init_backend', 'reset', 2);
-- segment 0 report an error when get the second request (reader gang creation request)
select gp_inject_fault('send_qe_details_init_backend', 'error', '', '', '', 3, 0, 2::smallint);

-- expect failure
select * from dispatch_test_t1, dispatch_test_t2, dispatch_test_t3
where dispatch_test_t1.c2 = dispatch_test_t2.c2 and dispatch_test_t2.c3 = dispatch_test_t3.c3;

-- expect resuable gang exist
select * from hasGangsExist();

-- expect QEs exist.
select sum(case when hasBackendsExist(0)='t' then 1 else 0 end) > 0 as hasbackends from gp_dist_random('gp_id');

select gp_inject_fault('send_qe_details_init_backend', 'reset', 2);

-- Case 1.4
-- Test createGang timeout.
-- gp_segment_connect_timeout = 0 : wait forever
-- gp_segment_connect_timeout = 1 : wait 1 second
set gp_segment_connect_timeout to 1;
select gp_inject_fault_new('process_startup_packet', 'suspend', '', 'dispatch_test_db', '', 1, 1, 0, 2::smallint);

select cleanupAllGangs();

-- expect timeout failure
select * from dispatch_test_t1, dispatch_test_t2, dispatch_test_t3
where dispatch_test_t1.c2 = dispatch_test_t2.c2 and dispatch_test_t2.c3 = dispatch_test_t3.c3;

select gp_inject_fault('process_startup_packet', 'resume', 2);
select gp_inject_fault('process_startup_packet', 'reset', 2);

set gp_segment_connect_timeout to 0;
select cleanupAllGangs();

select gp_inject_fault('process_startup_packet', 'sleep', '', '', '', 1, 1, 2::smallint);

-- expect success 
select * from dispatch_test_t1, dispatch_test_t2, dispatch_test_t3
where dispatch_test_t1.c2 = dispatch_test_t2.c2 and dispatch_test_t2.c3 = dispatch_test_t3.c3;

select gp_inject_fault('process_startup_packet', 'reset', 2);

-- Case 1.5
-- query was cancelled when dispatching commands to one gang.
-- query should be cancelled as expected.

-- must set log_min_messages to default when using interrupt, there is a bug in fault injection.
set log_min_messages to default;

select gp_inject_fault('after_one_slice_dispatched', 'interrupt', 1);

-- should fail and report error
select * from dispatch_test_t1, dispatch_test_t2, dispatch_test_t3
where dispatch_test_t1.c2 = dispatch_test_t2.c2 and dispatch_test_t2.c3 = dispatch_test_t3.c3;

select gp_inject_fault('after_one_slice_dispatched', 'reset', 1);

-- test logging of gang management
SET gp_log_gang = 'debug';

-- test INFO raised from segments with various kinds of fields
CREATE OR REPLACE FUNCTION udf_raise_info() RETURNS BOOL
AS '@abs_builddir@/regress@DLSUFFIX@', 'gangRaiseInfo' LANGUAGE C;

SELECT udf_raise_info() FROM gp_dist_random('gp_id') WHERE gp_segment_id = 0;

--
-- Error out when dispatching DTX command to busy primary writer gang
--
CREATE TABLE dtx_dispatch_t AS SELECT i AS c1 FROM generate_series(1,10) i;

CREATE or REPLACE FUNCTION dtx_dispatch_f(integer)
RETURNS INTEGER
AS
$$
BEGIN
        return $1 + 1;
EXCEPTION
        WHEN division_by_zero THEN
        RAISE NOTICE 'caught division_by_zero';
        return 0;
END
$$
LANGUAGE plpgSQL READS SQL DATA;

SELECT dtx_dispatch_f(foo.c1) FROM (SELECT c1 FROM dtx_dispatch_t WHERE c1='1' limit 1) foo;

DROP FUNCTION dtx_dispatch_f(integer);
DROP TABLE dtx_dispatch_t;

-- Test interconnect is shut down under portal failure
CREATE OR REPLACE FUNCTION numActiveMotionConns() RETURNS INT
AS '@abs_builddir@/regress@DLSUFFIX@', 'numActiveMotionConns' LANGUAGE C;

CREATE TABLE foo_test AS SELECT i AS c1 FROM generate_series(1, 10) i;

SELECT c1/0 FROM foo_test WHERE c1 = 1;
SELECT numActiveMotionConns();

BEGIN;
DECLARE C1 CURSOR FOR SELECT * FROM foo_test;
FETCH BACKWARD 1 FROM C1;
END;

SELECT numActiveMotionConns();

DROP FUNCTION numActiveMotionConns();
DROP TABLE foo_test;

--
-- Test dangling Gang would be destroyed if interrupted during the creation
--
select cleanupAllGangs();
select gp_inject_fault('gang_created', 'reset', 1);
-- The _new() API ensures that the fault is triggered exactly once.
select gp_inject_fault_new('gang_created', 'error', 1);
select 1 from gp_dist_random('gp_id') limit 1;
-- if previous gang is not destroyed, snapshot collision would happen
select 1 from gp_dist_random('gp_id') limit 1;
select gp_inject_fault('gang_created', 'reset', 1);

--
-- Test when error happens in createGang, it can correctly clean up
--
select cleanupAllGangs();
select gp_inject_fault('gang_created', 'reset', 1);
select gp_inject_fault('gang_created', 'skip', 1);
select 1 from gp_dist_random('gp_id') limit 1;
select gp_inject_fault('gang_created', 'reset', 1);
select 1 from gp_dist_random('gp_id') limit 1;

--
-- Test that an error happens after a big command is dispatched.
--
select gp_inject_fault('after_one_slice_dispatched', 'error', 1);
select * from gp_dist_random('gp_id')
	where gpname > (select * from repeat('sssss', 10000000));
select gp_inject_fault('after_one_slice_dispatched', 'reset', 1);
select * from gp_dist_random('gp_id')
	where gpname > (select * from repeat('sssss', 10000000));

--
-- Test portal cleanup
-- prepare a query contains init plan, main plan create a unnamed portal
-- and will need multiple slices , init plan also need to allocated multiple
-- slices in a named portal (eg: a cursor). The executing order is:
-- 1. gangs of main plan is pre-assigned 2. init plan is executed 3. main plan
-- is executed. This test it meant to test that cleanup of the named portal in
-- the end of step2 will not affect the pre-allocated gangs of the main plan.
--
create table foo (c1 int, c2 int);
create table bar (c1 int, c2 int);
create or replace function foo_func()
returns int
as
$BODY$
declare
t_record record;
BEGIN
	drop table if exists tmp1;
	create temp table tmp1 as select foo.c1, bar.c2 from foo, bar;
	for t_record in (select count(*) from foo, bar)
	loop
		NULL;
	end loop;
	return 1;
END;
$BODY$
language plpgsql volatile;
set gp_cached_segworkers_threshold to 1;
select count(*) from foo, bar where exists (select foo_func());
reset gp_cached_segworkers_threshold;
\c regression
DROP DATABASE dispatch_test_db;
