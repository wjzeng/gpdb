<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Composite//EN" "ditabase.dtd">
<topic id="topic22">
   <title>Specify gphdfs Protocol in an External Table Definition (Deprecated)</title>
   <body>
      <p>The <codeph>gphdfs</codeph>
         <codeph>LOCATION</codeph> clause of the <codeph>CREATE EXTERNAL TABLE</codeph> command for
         HDFS files differs slightly for Hadoop HA (High Availability) clusters, Hadoop clusters
         without HA, and MapR clusters. </p>
      <p>In a Hadoop HA cluster, the <codeph>LOCATION</codeph> clause references the logical
         nameservices id (the <codeph>dfs.nameservices</codeph> property in the
            <codeph>hdfs-site.xml</codeph> configuration file). The <codeph>hdfs-site.xml</codeph>
         file with the nameservices configuration must be installed on the Greenplum master and on
         each segment host.</p>
      <p>For example, if <codeph>dfs.nameservices</codeph> is set to <codeph>mycluster</codeph> the
            <codeph>LOCATION</codeph> clause takes this format:
         <codeblock>LOCATION ('gphdfs://mycluster/path/filename.txt')</codeblock></p>
      <p>A cluster without HA specifies the hostname and port of the name node in the
            <codeph>LOCATION</codeph> clause:
         <codeblock>LOCATION ('gphdfs://hdfs_host[:port]/path/filename.txt')</codeblock></p>
      <p>If you are using MapR clusters, you specify a specific cluster and the file:<ul
            id="ul_xdj_wzt_hq">
            <li>To specify the default cluster, the first entry in the MapR configuration file
                  <codeph>/opt/mapr/conf/mapr-clusters.conf</codeph>, specify the location of your
               table with this
               syntax:<codeblock>LOCATION ('gphdfs:///<varname>file_path</varname>')</codeblock> The
                  <varname>file_path</varname> is the path to the file.</li>
            <li>To specify another MapR cluster listed in the configuration file, specify the file
               with this syntax:
               <codeblock>LOCATION ('gphdfs:///mapr/<varname>cluster_name</varname>/<varname>file_path</varname>')</codeblock>The
                  <varname>cluster_name</varname> is the name of the cluster specified in the
               configuration file and <varname>file_path</varname> is the path to the file.</li>
         </ul></p>
      <p>For information about MapR clusters, see the MapR documentation.</p>
      <p>Restrictions for <codeph>HDFS</codeph> files are as follows.<ul id="ul_cmd_wxz_h4">
            <li id="du177803">You can specify one path for a readable external table with
                  <codeph>gphdfs</codeph>. Wildcard characters are allowed. If you specify a
               directory, the default is all files in the directory. <p>You can specify only a
                  directory for writable external tables.</p></li>
            <li>The URI of the <codeph>LOCATION</codeph> clause cannot contain any of these four
               characters: <codeph>\</codeph>, <codeph>'</codeph>, <codeph>&lt;</codeph>,
                  <codeph>></codeph>. The <codeph>CREATE EXTERNAL TABLE</codeph> returns a an error
               if the URI contains any of the characters.</li>
            <li id="du172453">Format restrictions are as follows.<ul id="ul_lr5_x1b_kp">
                  <li id="du192074">Only the <codeph>gphdfs_import</codeph> formatter is allowed for
                     readable external tables with a custom format.</li>
                  <li id="du192124">Only the <codeph>gphdfs_export</codeph> formatter is allowed for
                     writable external tables with a custom format.</li>
                  <li id="du189101">You can set compression only for writable external tables.
                     Compression settings are automatic for readable external tables.</li>
               </ul></li>
         </ul></p>
   </body>
   <topic id="topic23">
      <title>Setting Compression Options for Hadoop Writable External Tables</title>
      <body>
         <p>Compression options for Hadoop Writable External Tables use the form of a URI query and
            begin with a question mark. Specify multiple compression options with an ampersand
               (<codeph>&amp;</codeph>).</p>
         <table id="table_rl5_2yv_vs">
            <title>Compression Options</title>
            <tgroup cols="3">
               <colspec colnum="1" colname="col1" colwidth="1*"/>
               <colspec colnum="2" colname="col2" colwidth="1*"/>
               <colspec colnum="3" colname="col3" colwidth="2*"/>
               <thead>
                  <row>
                     <entry colname="col1">Compression Option</entry>
                     <entry colname="col2">Values</entry>
                     <entry colname="col3">Default Value</entry>
                  </row>
               </thead>
               <tbody>
                  <row>
                     <entry colname="col1">compress</entry>
                     <entry colname="col2"><codeph>true</codeph> or <codeph>false</codeph>
                     </entry>
                     <entry colname="col3">
                        <codeph>false</codeph>
                     </entry>
                  </row>
                  <row>
                     <entry colname="col1">compression_type</entry>
                     <entry colname="col2"><codeph>BLOCK</codeph> or <codeph>RECORD</codeph>
                     </entry>
                     <entry colname="col3">
                        <codeph>RECORD</codeph>
                        <p>For <codeph>AVRO</codeph> format, <codeph>compression_type</codeph> must
                           be <codeph>block</codeph> if <codeph>compress</codeph> is
                              <codeph>true</codeph>. </p>
                     </entry>
                  </row>
                  <row>
                     <entry colname="col1">codec</entry>
                     <entry colname="col2">Codec class name</entry>
                     <entry colname="col3"><codeph>GzipCodec</codeph> for <codeph>text</codeph>
                        format and <codeph>DefaultCodec</codeph> for <codeph>gphdfs_export</codeph>
                           format.<p>For <codeph>AVRO</codeph> format, the value is either
                              <codeph>deflate</codeph> (the default) or
                        <codeph>snappy</codeph></p></entry>
                  </row>
                  <row>
                     <entry colname="col1">codec_level (for <codeph>AVRO</codeph> format and
                           <codeph>deflate</codeph> codec only)</entry>
                     <entry colname="col2">integer between 1 and 9</entry>
                     <entry colname="col3">
                        <codeph>6</codeph>
                        <p>The level controls the trade-off between speed and compression. Valid
                           values are 1 to 9, where 1 is the fastest and 9 is the most compressed.
                        </p>
                     </entry>
                  </row>
               </tbody>
            </tgroup>
         </table>
         <p>Place compression options in the query portion of the URI.</p>
      </body>
   </topic>
</topic>
